replicaCount: 2

image:
  repository: quay.io/mittwald/kube-httpcache
  pullPolicy: Always
  tag: "stable"


nameOverride: "frontend-cache"
fullnameOverride: "frontend-varnish-httpcache"

# Enable StatefulSet (Deployment is default)
useStatefulset:
  enabled: true

# Enable configMap for Varnish Template File (see below vclTemplate)
# OR use extravolume with name "template" if the file is too big
configmap:
  enabled: true

# kube-httpcache specific configuration
cache:
  # name of frontend service
  # frontendService: kube-httpcache-headless
  # name of backend service
  backendService: skind-minotar-skind
  # name of backend service namespace
  # backendServiceNamespace: backend-service-namespace
  # watching for frontend changes is true by default
  frontendWatch: true
  # watching for backend changes is true by default
  backendWatch: true
  # Varnish storage backend type (https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)
  varnishStorage: file,/cache/varnish-cache # default,malloc,umem,file...
  # Varnish storage backend size
  storageSize: 2G # K(ibibytes), M(ebibytes), G(ibibytes), T(ebibytes) ... unlimited
  # Varnish transient storage backend type (https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)
  varnishTransientStorage: malloc
  # Varnish transient storage backend size
  transientStorageSize: 32M # K(ibibytes), M(ebibytes), G(ibibytes), T(ebibytes) ... unlimited
  # Secret for Varnish admin credentials
  secret: "this_is_not_publicly_accessible"
  # Read admin credentials from user provided secret
  #existingSecret: kubecache-secret

cacheExtraArgs: {}
# cacheExtraArgs: |
  # - -v=8
  # - -varnish-additional-parameters=vcc_allow_inline_c=on

extraVolumes:
  - name: file-cache
    emptyDir: {}

extraMounts:
  - name: file-cache
    mountPath: /cache/varnish-cache

exporter:
  enabled: true
  resources:
    limits:
      memory: 25Mi
    requests:
      cpu: 10m
      memory: 10Mi
serviceMonitor: true

service:
  type: ClusterIP
  port: 80
  target: 8080

resources:
  limits:
    memory: 1Gi
  requests:
    cpu: 75m
    memory: 500Mi


affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        topologyKey: "kubernetes.io/hostname"
        labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - frontend-cache
          - key: app.kubernetes.io/instance
            operator: In
            values:
            - frontend-varnish


livenessProbe: {}
# livenessProbe:
#   httpGet:
#    path: /
#    port: 6083
readinessProbe: {}

vclTemplate: |
  vcl 4.0;

  import std;
  import directors;

  // ".Frontends" is a slice that contains all known Varnish instances
  // (as selected by the service specified by -frontend-service).
  // The backend name needs to be the Pod name, since this value is compared
  // to the server identity ("server.identity" [1]) later.
  //
  //   [1]: https://varnish-cache.org/docs/6.4/reference/vcl.html#local-server-remote-and-client
  {{ range .Frontends }}
  backend {{ .Name }} {
      .host = "{{ .Host }}";
      .port = "{{ .Port }}";
  }
  {{- end }}

  {{ range .Backends }}
  backend be-{{ .Name }} {
      .host = "{{ .Host }}";
      .port = "{{ .Port }}";
  }
  {{- end }}

  backend svc-processd-minotar-processd {
      .host = "processd-minotar-processd";
      .port = "80";
  }

  #backend svc-frontend-website-minotar-caddy {
  #    .host = "frontend-website-minotar-caddy";
  #    .port = "80";
  #}

  sub vcl_init {
      // Statefulset Varnish Instances
      new cluster = directors.hash();
      {{ range .Frontends -}}
      cluster.add_backend({{ .Name }}, 1);
      {{ end }}

      // skind backend servers
      new lb-skind = directors.hash();
      {{ range .Backends -}}
      lb-skind.add_backend(be-{{ .Name }}, 1);
      {{ end }}

  }

  sub sanitize_incoming
  {

      # If not for the server_name && not the server_name redirect then we can drop it.
      #if (req.http.host != "minotar.net" && req.http.host != "minotar.net:80" && req.http.host != "www.minotar.net") {
      #  return (synth(403, "Forbidden"));
      #}

      # Let's remove all query strings, ampersands and hashes
      # These should not appear in any requests and are unrequired.
      if (req.url ~ "\?|&|#") {
        set req.url = regsub(req.url, "(\?|&|\#).*$", "");
      }

      # Remove all cookies
      unset req.http.cookie;

  }

  sub vcl_recv
  {
      # Default everything to primary backend
      set req.backend_hint = svc-processd-minotar-processd;

      call sanitize_incoming;

      # Redirect www to no-www and keep the URI
      if (req.http.host == "www.minotar.net") {
        # Handle HTTP/S by looking for the X-Forwarded-Proto header.
        if (req.http.x-forwarded-proto == "https") {
            return (synth(720, "https://minotar.net" + req.url));
        } else {
            return (synth(720, "http://minotar.net" + req.url));
        }
      }

      #if (req.url == "/webhook/github") {
      #  set req.backend_hint = svc-frontend-website-minotar-caddy;
      #  return (pass);
      #}

      # Only deal with GET and HEAD, 405 if not
      if (req.method != "GET" &&
          req.method != "HEAD") {
        return (synth(405, "GET, HEAD"));
      }

      #if (req.url == "/" || req.url == "/favicon.ico" || req.url == "/robots.txt" || req.url == "/404.html" || req.url ~ "^/assets/" || req.url ~ "^/addons/") {
      #  set req.backend_hint = svc-frontend-website-minotar-caddy;
      #  return (pass);
      #}

      # Remove the resource type from the URL for calculating the hash
      # (eg. so hash is only the last part of the URL - the Username/UUID so we always query same skind)
      set req.http.X-Req-Hash = regsub(req.url, ".*/(\w+)$", "\1");

      # Sharded Varnish Routing logic. Pass a request to an appropriate Varnish node.
      # See https://info.varnish-software.com/blog/creating-self-routing-varnish-cluster for more info.
      unset req.http.x-cache;
      set req.backend_hint = cluster.backend(req.http.X-Req-Hash);
      set req.http.x-shard = req.backend_hint;
      if (req.http.x-shard != server.identity) {
          return(pass);
      }

      ## Request was meant for this Varnish shard

      // Do we send directly to skind?
      if (req.url ~ "^/skin/" || req.url ~ "^/download/") {
        set req.backend_hint = lb-skind.backend(req.http.X-Req-Hash);
        return(hash);
      }

      # Must be processd URL
      set req.backend_hint = svc-processd-minotar-processd;

      return(hash);
  }

  # Handle the HTTP request coming from our backend
  sub vcl_backend_response
  {
      # Called after the response headers has been successfully retrieved from the backend.

      # Remove all cookies, cache everything
      unset beresp.http.Set-Cookie;

      # Return backend name with each request
      if (beresp.http.X-Backend) {
        set beresp.http.X-Backend = beresp.http.X-Backend + ", " + beresp.backend.name;
      } else {
        set beresp.http.X-Backend = beresp.backend.name;
      }

      # How many attempts it took to get the resource
      if (bereq.retries > 0) {
        set beresp.http.X-Attempts = bereq.retries + 1;
      }

      # Allow stale content, in case the backend goes down.
      # make Varnish keep all objects for 1.5 hours beyond their TTL
      set beresp.grace = 30m;
      # Keep optimizes If-None-Match
      set beresp.keep = 1h;

      return (deliver);
  }

  # If things go wrong on request to the backend
  sub vcl_backend_error
  {
      set beresp.http.X-Attempts = bereq.retries + 1;

      if (beresp.status == 503 && bereq.retries < 4) {
        return (retry);
      }


      # At this point we have tried 5 times to hit the backend and sill failed :(
      set beresp.http.Content-Type = "text/html; charset=utf-8";
      set beresp.http.Retry-After = "5";
      synthetic( {"<!DOCTYPE html>
    <html>
      <head>
        <title>"} + beresp.status + " " + beresp.reason + {"</title>
      </head>
      <body>
        <h1>Error "} + beresp.status + " " + beresp.reason + {"</h1>
        <p>"} + beresp.reason + {"</p>
        <h3>Guru Minotation:</h3>
        <p>XID: "} + bereq.xid + {"</p>
        <hr>
        <p>Varnish cache server</p>
      </body>
    </html>
    "} );
      return (deliver);
  }

  sub vcl_deliver
  {
      # Called before a cached object is delivered to the client.

      # Set debug info headers
      set resp.http.X-Req-Hash = req.http.X-Req-Hash;

      set resp.http.X-Varnish-Server = server.identity;

      # Only add the object headers when it was served by this shard
      if (req.http.x-shard == server.identity) {
        if (obj.hits > 0) { # Add debug header to see if it's a HIT/MISS and the number of hits, disable when not needed
          set resp.http.X-Cache = "HIT";
        } else {
          set resp.http.X-Cache = "MISS";
        }

        if (req.http.grace) {
          set resp.http.X-Grace = req.http.grace;
        }

        # Please note that obj.hits behaviour changed in 4.0, now it counts per objecthead, not per object
        # and obj.hits may not be reset in some cases where bans are in use. See bug 1492 for details.
        # So take hits with a grain of salt
        set resp.http.X-Cache-Hits = obj.hits;
      }

      call header_cleanup;
  }

  sub vcl_synth
  {
      if (resp.status == 720) {
        # We use this special error status 720 to force redirects with 301 (permanent) redirects
        # To use this, call the following from anywhere in vcl_recv: return (synth(720, "http://host/new.html"));
        set resp.http.Location = resp.reason;
        set resp.status = 301;
      } elseif (resp.status == 721) {
        # And we use error status 721 to force redirects with a 302 (temporary) redirect
        # To use this, call the following from anywhere in vcl_recv: return (synth(720, "http://host/new.html"));
        set resp.http.Location = resp.reason;
        set resp.status = 302;
      } elseif (resp.status == 405) {
        set resp.http.Allow = resp.reason;
        set resp.status = 405;
      }

      call header_cleanup;
  }


  # Header cleanup and removal for headers which we don't want making it to the clients.
  sub header_cleanup
  {
      unset resp.http.X-Powered-By;
      unset resp.http.Server;
      unset resp.http.X-Drupal-Cache;
      unset resp.http.X-Varnish;
      unset resp.http.Via;
      unset resp.http.Link;
      unset resp.http.X-Generator;

      return (deliver);
  }
